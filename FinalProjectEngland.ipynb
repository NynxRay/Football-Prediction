{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import time\n",
    "import random\n",
    "\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Calculate accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#SVM\n",
    "from sklearn import svm\n",
    "\n",
    "#Neural Nets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# We have to use and MODIFY a lot the pre-processing method borrowed from another library to maximum our use of the dataset\n",
    "# because it is a huge raw dataset and it is not in the form we need for our project. \n",
    "# https://github.com/llSourcell/Predicting_Winning_Teams\n",
    "# Except for loading the data, everything else is orginal\n",
    "# There will be a clear mark where our pure original code starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FTR  HTP  ATP HM1 HM2 HM3 AM1 AM2 AM3  HTGD  ATGD  DiffFormPts  DiffLP\n",
       "0   H  0.0  0.0   M   M   M   M   M   M   0.0   0.0          0.0     0.0\n",
       "1   H  0.0  0.0   M   M   M   M   M   M   0.0   0.0          0.0    -4.0\n",
       "2  NH  0.0  0.0   M   M   M   M   M   M   0.0   0.0          0.0     2.0\n",
       "3  NH  0.0  0.0   M   M   M   M   M   M   0.0   0.0          0.0     1.0\n",
       "4   H  0.0  0.0   M   M   M   M   M   M   0.0   0.0          0.0   -10.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read data and drop redundant column.\n",
    "data = pd.read_csv('Egfinal_dataset.csv')\n",
    "data = data.filter(['FTR','HTP','ATP','HM1','HM2','HM3','AM1','AM2','AM3','HTGD','ATGD','DiffFormPts','DiffLP'], axis=1)\n",
    "\n",
    "# Preview data.\n",
    "display(data.head())\n",
    "\n",
    "\n",
    "#Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "#HTGD - Home team goal difference\n",
    "#ATGD - away team goal difference\n",
    "#HTP - Home team points\n",
    "#ATP - Away team points\n",
    "#DiffFormPts Diff in points\n",
    "#DiffLP - Differnece in last years prediction\n",
    "\n",
    "#Input - 12 other features (fouls, shots, goals, misses,corners, red card, yellow cards)\n",
    "#Output - Full Time Result (H=Home Win, NH = Away win) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of matches: 6080\n",
      "Number of features: 12\n",
      "Number of matches won by home team: 2816\n",
      "Win rate of home team: 46.32%\n"
     ]
    }
   ],
   "source": [
    "#what is the win rate for the home team?\n",
    "\n",
    "# Total number of matches.\n",
    "n_matches = data.shape[0]\n",
    "\n",
    "# Calculate number of features. -1 because we are saving one as the target variable (win/lose/draw)\n",
    "n_features = data.shape[1] - 1\n",
    "\n",
    "# Calculate matches won by home team.\n",
    "n_homewins = len(data[data.FTR == 'H'])\n",
    "\n",
    "# Calculate win rate for home team.\n",
    "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of matches: {}\".format(n_matches))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of matches won by home team: {}\".format(n_homewins))\n",
    "print(\"Win rate of home team: {:.2f}%\".format(win_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: 'pandas.tools.plotting.scatter_matrix' is deprecated, import 'pandas.plotting.scatter_matrix' instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0024438>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0348710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0374BA8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C03A6278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C03CE908>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C03CE940>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0424668>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C044ECF8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C047F3C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C04A3A58>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C04D7128>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C04FF7B8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0525E48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0554518>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0580BA8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C05B2278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C05D5908>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0600F98>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0630668>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0656CF8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C06883C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C06B0A58>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C06E2128>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C070A7B8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0731E48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0762518>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0787BA8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C07BA278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C07E1908>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0809F98>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000244C083D668>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C0863CF8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C08953C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C08BCA58>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C08ED128>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000244C09127B8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualising distribution of data\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "#the scatter matrix is plotting each of the columns specified against each other column.\n",
    "#You would have observed that the diagonal graph is defined as a histogram, which means that in the \n",
    "#section of the plot matrix where the variable is against itself, a histogram is plotted.\n",
    "\n",
    "#Scatter plots show how much one variable is affected by another. \n",
    "#The relationship between two variables is called their correlation\n",
    "#negative vs positive correlation\n",
    "\n",
    "#HTGD - Home team goal difference\n",
    "#ATGD - away team goal difference\n",
    "#HTP - Home team points\n",
    "#ATP - Away team points\n",
    "#DiffFormPts Diff in points\n",
    "#DiffLP - Differnece in last years prediction\n",
    "\n",
    "scatter_matrix(data[['HTGD','ATGD','HTP','ATP','DiffFormPts','DiffLP']], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into feature set and target variable\n",
    "#FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "X_all = data.drop(['FTR'],1)\n",
    "y_all = data['FTR']\n",
    "\n",
    "# Standardising the data.\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#Center to the mean and component wise scale to unit variance.\n",
    "cols = [['HTGD','ATGD','HTP','ATP','DiffLP']]\n",
    "for col in cols:\n",
    "    X_all[col] = scale(X_all[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (30 total features):\n",
      "['HTP', 'ATP', 'HM1_D', 'HM1_L', 'HM1_M', 'HM1_W', 'HM2_D', 'HM2_L', 'HM2_M', 'HM2_W', 'HM3_D', 'HM3_L', 'HM3_M', 'HM3_W', 'AM1_D', 'AM1_L', 'AM1_M', 'AM1_W', 'AM2_D', 'AM2_L', 'AM2_M', 'AM2_W', 'AM3_D', 'AM3_L', 'AM3_M', 'AM3_W', 'HTGD', 'ATGD', 'DiffFormPts', 'DiffLP']\n"
     ]
    }
   ],
   "source": [
    "#last 3 wins for both sides\n",
    "X_all.HM1 = X_all.HM1.astype('str')\n",
    "X_all.HM2 = X_all.HM2.astype('str')\n",
    "X_all.HM3 = X_all.HM3.astype('str')\n",
    "X_all.AM1 = X_all.AM1.astype('str')\n",
    "X_all.AM2 = X_all.AM2.astype('str')\n",
    "X_all.AM3 = X_all.AM3.astype('str')\n",
    "\n",
    "#we want continous vars that are integers for our input data, so lets remove any categorical vars\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the football data and converts catagorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "#Here below is all original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_classifier(train_X,train_Y,test_X,test_Y):\n",
    "    abc = AdaBoostClassifier(n_estimators=50)\n",
    "    abc.fit(train_X,train_Y)\n",
    "    trainAccuracy = abc.score(train_X,train_Y)\n",
    "    pred = abc.predict(test_X)\n",
    "    accuracy = metrics.accuracy_score(test_Y,pred)\n",
    "    return accuracy,trainAccuracy\n",
    "    \n",
    "def RandomForest_classifier(train_X,train_Y,test_X,test_Y):\n",
    "    \n",
    "    clf=RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "    clf.fit(train_X,train_Y)\n",
    "    trainAccuracy = clf.score(train_X,train_Y)\n",
    "    y_pred = clf.predict(test_X)\n",
    "    accuracy = metrics.accuracy_score(test_Y,y_pred)\n",
    "    return accuracy, trainAccuracy\n",
    "\n",
    "def SVM_classifier(train_X,train_Y,test_X,test_Y):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_X, train_Y)\n",
    "    trainAccuracy = clf.score(train_X,train_Y)\n",
    "    y_pred = clf.predict(test_X)\n",
    "    accuracy = metrics.accuracy_score(test_Y,y_pred)\n",
    "    return accuracy,trainAccuracy\n",
    "    \n",
    "def KNN_classifier(train_X,train_Y,test_X,test_Y):\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "    neigh.fit(train_X, train_Y)\n",
    "    trainAccuracy = neigh.score(train_X,train_Y)\n",
    "    y_pred = neigh.predict(test_X)\n",
    "    accuracy = metrics.accuracy_score(test_Y,y_pred)\n",
    "    return accuracy,trainAccuracy\n",
    "    \n",
    "def NeuralNets_classifier(train_X,train_Y,test_X,test_Y):\n",
    "    \n",
    "    clf = MLPClassifier(hidden_layer_sizes=(10, 2), learning_rate_init=0.0001,max_iter=200)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    trainAccuracy = clf.score(train_X,train_Y)\n",
    "    y_pred = clf.predict(test_X)\n",
    "    accuracy = metrics.accuracy_score(test_Y,y_pred)\n",
    "    return accuracy,trainAccuracy\n",
    "\n",
    "def NaiveBayes_classifier(train_X,train_Y,test_X,test_Y):\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_X, train_Y)\n",
    "    trainAccuracy = gnb.score(train_X,train_Y)\n",
    "    y_pred = gnb.predict(test_X)\n",
    "    accuracy = metrics.accuracy_score(test_Y,y_pred)\n",
    "    return accuracy,trainAccuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AdaBoost takes 0.8012905120849609 seconds ---\n",
      "--- RandomForest takes 0.139418363571167 seconds ---\n",
      "--- KNN takes 1.2809033393859863 seconds ---\n",
      "--- SVM takes 3.678386688232422 seconds ---\n",
      "--- Neural Nets takes 2.4955196380615234 seconds ---\n",
      "--- Naive Bayes takes 0.04683566093444824 seconds ---\n",
      "TRAINING\n",
      "Accuracy for AdaBoost: 0.6749588815789473\n",
      "Accuracy for RandomForest: 0.6504934210526315\n",
      "Accuracy for KNN: 0.7808388157894738\n",
      "Accuracy for svm: 0.6823601973684209\n",
      "Accuracy for Neural Nets: 0.6659128289473685\n",
      "Accuracy for Naive Bayes: 0.6517269736842105\n",
      "TESTING\n",
      "Accuracy for AdaBoost: 0.625\n",
      "Accuracy for RandomForest: 0.6488486842105263\n",
      "Accuracy for KNN: 0.5699013157894737\n",
      "Accuracy for svm: 0.6447368421052632\n",
      "Accuracy for Neural Nets: 0.6337719298245613\n",
      "Accuracy for Naive Bayes: 0.6414473684210527\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation # 80% 20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X,train_Y, test_Y = train_test_split(X_all,y_all,test_size=0.2)\n",
    "\n",
    "accuracy_SVM = []\n",
    "accuracy_AdaBoost = []\n",
    "accuracy_RandomForest = []\n",
    "accuracy_KNN = []\n",
    "accuracy_NN = []\n",
    "accuracy_NB = []\n",
    "\n",
    "train_SVM = []\n",
    "train_AdaBoost = []\n",
    "train_RandomForest = []\n",
    "train_KNN = []\n",
    "train_NN = []\n",
    "train_NB = []\n",
    "\n",
    "for i in range(3):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # AdaBoost Classifier\n",
    "        testAccuracy1, trainAccuracy1 = AdaBoost_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_AdaBoost.append(testAccuracy1)\n",
    "        train_AdaBoost.append(trainAccuracy1)\n",
    "\n",
    "        time1 = time.time()\n",
    "        if i == 1: \n",
    "            print(\"--- AdaBoost takes %s seconds ---\" % (time1 - start_time))\n",
    "            \n",
    "            \n",
    "        # RandomForest Classifier\n",
    "        testAccuracy2,trainAccuracy2 = RandomForest_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_RandomForest.append(testAccuracy2)\n",
    "        train_RandomForest.append(trainAccuracy2)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        if i== 1:\n",
    "            print(\"--- RandomForest takes %s seconds ---\" % (time2 - time1))\n",
    "        \n",
    "        # K-Nearest-Neighbour Classifier\n",
    "        testAccuracy3,trainAccuracy3 = KNN_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_KNN.append(testAccuracy3)\n",
    "        train_KNN.append(trainAccuracy3)\n",
    "        \n",
    "        time3 = time.time()\n",
    "        if i== 1:\n",
    "            print(\"--- KNN takes %s seconds ---\" % (time3 - time2))\n",
    "        \n",
    "        #SVM classifier\n",
    "        testAccuracy4, trainAccuracy4 = SVM_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_SVM.append(testAccuracy4)\n",
    "        train_SVM.append(trainAccuracy4)\n",
    "        \n",
    "        time4 = time.time()\n",
    "        if i==1:\n",
    "            print(\"--- SVM takes %s seconds ---\" % (time4 - time3))\n",
    "        \n",
    "        #Neural Nets classifier\n",
    "        testAccuracy5,trainAccuracy5 = NeuralNets_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_NN.append(testAccuracy5)\n",
    "        train_NN.append(trainAccuracy5)\n",
    "        \n",
    "        \n",
    "        time5 = time.time()\n",
    "        if i==1:\n",
    "            print(\"--- Neural Nets takes %s seconds ---\" % (time5 - time4))\n",
    "            \n",
    "        testAccuracy6,trainAccuracy6 = NaiveBayes_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_NB.append(testAccuracy6)\n",
    "        train_NB.append(trainAccuracy6)\n",
    "        \n",
    "        time6 = time.time()\n",
    "        if i==1:\n",
    "            print(\"--- Naive Bayes takes %s seconds ---\" % (time6 - time5))\n",
    "        \n",
    "print('TRAINING')        \n",
    "print(\"Accuracy for AdaBoost:\",np.mean(train_AdaBoost))\n",
    "print(\"Accuracy for RandomForest:\",np.mean(train_RandomForest))\n",
    "print(\"Accuracy for KNN:\",np.mean(train_KNN))\n",
    "print(\"Accuracy for svm:\",np.mean(train_SVM))\n",
    "print(\"Accuracy for Neural Nets:\",np.mean(train_NN))\n",
    "print(\"Accuracy for Naive Bayes:\",np.mean(train_NB))\n",
    "\n",
    "\n",
    "print('TESTING')\n",
    "print(\"Accuracy for AdaBoost:\",np.mean(accuracy_AdaBoost))\n",
    "print(\"Accuracy for RandomForest:\",np.mean(accuracy_RandomForest))\n",
    "print(\"Accuracy for KNN:\",np.mean(accuracy_KNN))\n",
    "print(\"Accuracy for svm:\",np.mean(accuracy_SVM))\n",
    "print(\"Accuracy for Neural Nets:\",np.mean(accuracy_NN))\n",
    "print(\"Accuracy for Naive Bayes:\",np.mean(accuracy_NB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AdaBoost takes 0.7290513515472412 seconds ---\n",
      "--- RandomForest takes 0.5465385913848877 seconds ---\n",
      "--- KNN takes 1.3314409255981445 seconds ---\n",
      "--- SVM takes 2.4534385204315186 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Neural Nets takes 3.1824893951416016 seconds ---\n",
      "--- Naive Bayes takes 0.03790092468261719 seconds ---\n",
      "TRAINING\n",
      "Accuracy for AdaBoost: 0.6723684210526316\n",
      "Accuracy for RandomForest: 0.6513157894736842\n",
      "Accuracy for KNN: 0.78125\n",
      "Accuracy for svm: 0.6750000000000002\n",
      "Accuracy for Neural Nets: 0.5508771929824562\n",
      "Accuracy for Naive Bayes: 0.6371710526315789\n",
      "TESTING\n",
      "Accuracy for AdaBoost: 0.6526315789473685\n",
      "Accuracy for RandomForest: 0.6434210526315789\n",
      "Accuracy for KNN: 0.5555921052631579\n",
      "Accuracy for svm: 0.6694078947368421\n",
      "Accuracy for Neural Nets: 0.550548245614035\n",
      "Accuracy for Naive Bayes: 0.6378289473684211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation # 50% 50%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X,train_Y, test_Y = train_test_split(X_all,y_all,test_size=0.5)\n",
    "\n",
    "accuracy_SVM = []\n",
    "accuracy_AdaBoost = []\n",
    "accuracy_RandomForest = []\n",
    "accuracy_KNN = []\n",
    "accuracy_NN = []\n",
    "accuracy_NB = []\n",
    "\n",
    "train_SVM = []\n",
    "train_AdaBoost = []\n",
    "train_RandomForest = []\n",
    "train_KNN = []\n",
    "train_NN = []\n",
    "train_NB = []\n",
    "\n",
    "for i in range(3):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # AdaBoost Classifier\n",
    "        testAccuracy1, trainAccuracy1 = AdaBoost_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_AdaBoost.append(testAccuracy1)\n",
    "        train_AdaBoost.append(trainAccuracy1)\n",
    "\n",
    "        time1 = time.time()\n",
    "        if i == 1: \n",
    "            print(\"--- AdaBoost takes %s seconds ---\" % (time1 - start_time))\n",
    "            \n",
    "            \n",
    "        # RandomForest Classifier\n",
    "        testAccuracy2,trainAccuracy2 = RandomForest_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_RandomForest.append(testAccuracy2)\n",
    "        train_RandomForest.append(trainAccuracy2)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        if i== 1:\n",
    "            print(\"--- RandomForest takes %s seconds ---\" % (time2 - time1))\n",
    "        \n",
    "        # K-Nearest-Neighbour Classifier\n",
    "        testAccuracy3,trainAccuracy3 = KNN_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_KNN.append(testAccuracy3)\n",
    "        train_KNN.append(trainAccuracy3)\n",
    "        \n",
    "        time3 = time.time()\n",
    "        if i== 1:\n",
    "            print(\"--- KNN takes %s seconds ---\" % (time3 - time2))\n",
    "        \n",
    "        #SVM classifier\n",
    "        testAccuracy4, trainAccuracy4 = SVM_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_SVM.append(testAccuracy4)\n",
    "        train_SVM.append(trainAccuracy4)\n",
    "        \n",
    "        time4 = time.time()\n",
    "        if i==1:\n",
    "            print(\"--- SVM takes %s seconds ---\" % (time4 - time3))\n",
    "        \n",
    "        #Neural Nets classifier\n",
    "        testAccuracy5,trainAccuracy5 = NeuralNets_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_NN.append(testAccuracy5)\n",
    "        train_NN.append(trainAccuracy5)\n",
    "        \n",
    "        \n",
    "        time5 = time.time()\n",
    "        if i==1:\n",
    "            print(\"--- Neural Nets takes %s seconds ---\" % (time5 - time4))\n",
    "          \n",
    "        # Naive Bayes\n",
    "        testAccuracy6,trainAccuracy6 = NaiveBayes_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_NB.append(testAccuracy6)\n",
    "        train_NB.append(trainAccuracy6)\n",
    "        \n",
    "        time6 = time.time()\n",
    "        if i==1:\n",
    "            print(\"--- Naive Bayes takes %s seconds ---\" % (time6 - time5))\n",
    "        \n",
    "print('TRAINING')        \n",
    "print(\"Accuracy for AdaBoost:\",np.mean(train_AdaBoost))\n",
    "print(\"Accuracy for RandomForest:\",np.mean(train_RandomForest))\n",
    "print(\"Accuracy for KNN:\",np.mean(train_KNN))\n",
    "print(\"Accuracy for svm:\",np.mean(train_SVM))\n",
    "print(\"Accuracy for Neural Nets:\",np.mean(train_NN))\n",
    "print(\"Accuracy for Naive Bayes:\",np.mean(train_NB))\n",
    "\n",
    "\n",
    "print('TESTING')\n",
    "print(\"Accuracy for AdaBoost:\",np.mean(accuracy_AdaBoost))\n",
    "print(\"Accuracy for RandomForest:\",np.mean(accuracy_RandomForest))\n",
    "print(\"Accuracy for KNN:\",np.mean(accuracy_KNN))\n",
    "print(\"Accuracy for svm:\",np.mean(accuracy_SVM))\n",
    "print(\"Accuracy for Neural Nets:\",np.mean(accuracy_NN))\n",
    "print(\"Accuracy for Naive Bayes:\",np.mean(accuracy_NB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AdaBoost takes 0.29324769973754883 seconds ---\n",
      "--- RandomForest takes 0.28324198722839355 seconds ---\n",
      "--- KNN takes 0.49564504623413086 seconds ---\n",
      "--- SVM takes 0.5674805641174316 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Neural Nets takes 1.0681450366973877 seconds ---\n",
      "--- Naive Bayes takes 0.03291177749633789 seconds ---\n",
      "TRAINING\n",
      "Accuracy for AdaBoost: 0.6875\n",
      "Accuracy for RandomForest: 0.6570723684210527\n",
      "Accuracy for KNN: 0.7771381578947368\n",
      "Accuracy for svm: 0.6899671052631579\n",
      "Accuracy for Neural Nets: 0.5550986842105262\n",
      "Accuracy for Naive Bayes: 0.6554276315789473\n",
      "TESTING\n",
      "Accuracy for AdaBoost: 0.6295230263157895\n",
      "Accuracy for RandomForest: 0.6428865131578947\n",
      "Accuracy for KNN: 0.5657894736842105\n",
      "Accuracy for svm: 0.6543996710526315\n",
      "Accuracy for Neural Nets: 0.551672149122807\n",
      "Accuracy for Naive Bayes: 0.6435032894736842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation # 20% 80%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X,train_Y, test_Y = train_test_split(X_all,y_all,test_size=0.8)\n",
    "\n",
    "accuracy_SVM = []\n",
    "accuracy_AdaBoost = []\n",
    "accuracy_RandomForest = []\n",
    "accuracy_KNN = []\n",
    "accuracy_NN = []\n",
    "accuracy_NB = []\n",
    "\n",
    "train_SVM = []\n",
    "train_AdaBoost = []\n",
    "train_RandomForest = []\n",
    "train_KNN = []\n",
    "train_NN = []\n",
    "train_NB = []\n",
    "\n",
    "for i in range(3):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # AdaBoost Classifier\n",
    "        testAccuracy1, trainAccuracy1 = AdaBoost_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_AdaBoost.append(testAccuracy1)\n",
    "        train_AdaBoost.append(trainAccuracy1)\n",
    "\n",
    "        time1 = time.time()\n",
    "        if i == 1: \n",
    "            print(\"--- AdaBoost takes %s seconds ---\" % (time1 - start_time))\n",
    "            \n",
    "            \n",
    "        # RandomForest Classifier\n",
    "        testAccuracy2,trainAccuracy2 = RandomForest_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_RandomForest.append(testAccuracy2)\n",
    "        train_RandomForest.append(trainAccuracy2)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        if i== 1:\n",
    "            print(\"--- RandomForest takes %s seconds ---\" % (time2 - time1))\n",
    "        \n",
    "        # K-Nearest-Neighbour Classifier\n",
    "        testAccuracy3,trainAccuracy3 = KNN_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_KNN.append(testAccuracy3)\n",
    "        train_KNN.append(trainAccuracy3)\n",
    "        \n",
    "        time3 = time.time()\n",
    "        if i== 1:\n",
    "            print(\"--- KNN takes %s seconds ---\" % (time3 - time2))\n",
    "        \n",
    "        #SVM classifier\n",
    "        testAccuracy4, trainAccuracy4 = SVM_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_SVM.append(testAccuracy4)\n",
    "        train_SVM.append(trainAccuracy4)\n",
    "        \n",
    "        time4 = time.time()\n",
    "        if i==1:\n",
    "            print(\"--- SVM takes %s seconds ---\" % (time4 - time3))\n",
    "        \n",
    "        #Neural Nets classifier\n",
    "        testAccuracy5,trainAccuracy5 = NeuralNets_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_NN.append(testAccuracy5)\n",
    "        train_NN.append(trainAccuracy5)\n",
    "        \n",
    "        \n",
    "        time5 = time.time()\n",
    "        if i==1:\n",
    "            print(\"--- Neural Nets takes %s seconds ---\" % (time5 - time4))\n",
    "        \n",
    "        # Naive Bayes    \n",
    "        testAccuracy6,trainAccuracy6 = NaiveBayes_classifier(train_X,train_Y,test_X,test_Y)\n",
    "        accuracy_NB.append(testAccuracy6)\n",
    "        train_NB.append(trainAccuracy6)\n",
    "        \n",
    "        time6 = time.time()\n",
    "        if i==1:\n",
    "            print(\"--- Naive Bayes takes %s seconds ---\" % (time6 - time5))\n",
    "        \n",
    "print('TRAINING')        \n",
    "print(\"Accuracy for AdaBoost:\",np.mean(train_AdaBoost))\n",
    "print(\"Accuracy for RandomForest:\",np.mean(train_RandomForest))\n",
    "print(\"Accuracy for KNN:\",np.mean(train_KNN))\n",
    "print(\"Accuracy for svm:\",np.mean(train_SVM))\n",
    "print(\"Accuracy for Neural Nets:\",np.mean(train_NN))\n",
    "print(\"Accuracy for Naive Bayes:\",np.mean(train_NB))\n",
    "\n",
    "\n",
    "print('TESTING')\n",
    "print(\"Accuracy for AdaBoost:\",np.mean(accuracy_AdaBoost))\n",
    "print(\"Accuracy for RandomForest:\",np.mean(accuracy_RandomForest))\n",
    "print(\"Accuracy for KNN:\",np.mean(accuracy_KNN))\n",
    "print(\"Accuracy for svm:\",np.mean(accuracy_SVM))\n",
    "print(\"Accuracy for Neural Nets:\",np.mean(accuracy_NN))\n",
    "print(\"Accuracy for Naive Bayes:\",np.mean(accuracy_NB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
